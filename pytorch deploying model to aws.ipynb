{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"!pip install pickle\nimport os, sys\nfrom time import time\n\nimport pandas as pd\nimport io\nimport requests\nimport numpy as np\nfrom sklearn import metrics\nimport boto3, re\n\nsagemaker_session = sagemaker.Session()\n\nbucket = sagemaker_session.default_bucket()\nprefix = 'sagemaker/DEMO-pytorch-mnist'\n\nrole = sagemaker.get_execution_role()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data\n### Getting the data\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom scipy.interpolate import interp1d\nfrom sklearn.metrics import roc_curve\nfrom torch.nn.utils import clip_grad_norm_\nfrom scipy.optimize import brentq\nfrom torch import nn\nimport torch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## loading the tensorflow model using saved_model file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# downloading the model file from s3 by download_fileobj()\nBUCKET_NAME = 'edu-1'\nFILE_NAME = 'efficientNetB3.h5'\nOBJECT_PATH = './edu-1/'+'efficientNetB3.h5'\n\ndef get_model():\n    s3 = boto3.client('s3')\n    with open(FILE_NAME, 'wb') as f:\n        s3.download_fileobj(BUCKET_NAME, OBJECT_PATH, f)\n    \n    # laoding the model\n    t1 = time()\n    \n    # if provide errors then get the model arcitecture\n#     model = TheNEtMODEL()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     model = torch.nn.DataParallel(Net())\n#     with open(OBJECT_PATH, 'rb') as f:\n#         model.load_state_dict(torch.load(f))\n    print(\"time for loading file size with pickle\", os.path.getsize(OBJECT_PATH)/1000,\"MB =>\", time()-t1)\n\n#     return model.to(device)\n\n# model = get_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: This directory structure will need to be followed - see notes for the next section\nmodel_version = '1'\nexport_path = 'export/Servo/' + model_version\n\nimport shutil\nshutil.rmtree(export_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.cpu().state_dict(), export_path)\n\nimport tarfile\nwith tarfile.open('model.tar.gz', mode='w:gz') as archive:\n    archive.add('export', recursive=True)","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'torch' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-bce5cf277d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# uploading tar to s3\nimport sagemaker\n\nsagemaker_session = sagemaker.Session()\ninputs = sagemaker_session.upload_data(path='model.tar.gz', key_prefix='model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 5. Deploy the trained model (must use AWS SageMaker Notebook)\n\nThe entry_point file \"train.py\" can be an empty Python file. The requirement will be removed at a later date."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"!touch train.py","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  you can train a model on a set of GPU-based instances, and then deploy the Endpoint to a fleet of CPU-based instances, but you need to make sure that you return or save your model as a cpu model"},{"metadata":{"trusted":false},"cell_type":"code","source":"# sagemaker.pytorch.model.PyTorchModel(model_data, role, entry_point, \n#                                      image=None, py_version='py3', framework_version=None, \n#                                      predictor_cls=<class 'sagemaker.pytorch.model.PyTorchPredictor'>, \n#                                      model_server_workers=None)\n\nfrom sagemaker.pytorch.model import PyTorchModel\n\nestimator = PyTorchModel(model_data = 's3://' + sagemaker_session.default_bucket() + '/model/model.tar.gz', \n                        role=role,    # an IAM role\n                        entry_point='train.py', \n                        py_version='py3', \n                        framework_version='1.3', \n                        model_server_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\npredictor = estimator.deploy(initial_instance_count=1, \n                             instance_type='ml.m4.xlarge')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor.endpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"endpoint_name = 'sagemaker-tensorflow-2019-08-05-03-29-25-591'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import sagemaker\nfrom sagemaker.pytorch.model import PyTorchPredictor\n\npredictor= PyTorchPredictor(endpoint_name, sagemaker_session)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 13.2.3: Test Model Deployment (optionally, outside of AWS)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport boto3\nimport numpy as np\nimport io","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### # Pick one of the following two cells to run based on how you will access..."},{"metadata":{"trusted":false},"cell_type":"code","source":"# # If you access the API from outside of AWS SageMaker notebooks you must authenticate and specify region...\n# # (do not run both this cell and the next)\n\n# client = boto3.client('runtime.sagemaker', \n#     region_name='us-east-1', # make sure to set correct region\n#     aws_access_key_id='AKIAYKSSG3L5P2H5EU77', # These you get from AWS, for your account\n#     aws_secret_access_key='1GYDRaE1o/nFfW2nF6jAJpWrd2R5Eut/d6fS6ruL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If you access from inside AWS in a notebook (do not run both this cell and the previous)\nclient = boto3.client('runtime.sagemaker', \n                      region_name='us-east-1') # make sure to set correct region","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Call the endpoint \n\ndata = [[8,307,130,3504,12,70,1]]\n\nresponse = client.invoke_endpoint(EndpointName=endpoint_name, \n                                  Body=json.dumps(data))\nresponse_body = response['Body']\nprint(response_body.read())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Environment (conda_pytorch_p27)","language":"python","name":"conda_pytorch_p27"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.14"},"notice":"Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."},"nbformat":4,"nbformat_minor":1}