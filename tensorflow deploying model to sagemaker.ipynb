{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Step 1. Set up\n\nIn the AWS Management Console, go to the Amazon SageMaker console. Choose Notebook Instances, and create a new notebook instance. Upload this notebook and set the kernel to conda_tensorflow_p36.\n\nThe get_execution_role function retrieves the AWS Identity and Access Management (IAM) role you created at the time of creating your notebook instance."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install pickle\nimport os, sys\nfrom time import time\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom tensorflow.python.saved_model import builder as saved_model_builder\nfrom tensorflow.python.saved_model import signature_constants\nfrom tensorflow.python.saved_model import signature_def_utils\nfrom tensorflow.python.saved_model import tag_constants\nfrom tensorflow.python.saved_model import utils\nfrom tensorflow.python.util import compat\n\nfrom tensorflow.python.saved_model import builder\nfrom tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n\n\nimport pandas as pd\nimport io\nimport requests\nimport numpy as np\nfrom sklearn import metrics\n\n\n\nimport boto3, re\nfrom sagemaker import get_execution_role\nimport sagemaker\n\n\nsagemaker_session = sagemaker.Session()\n\nrole = get_execution_role()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## loading the tensorflow model using saved_model file"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"# downloading the model file from s3 by download_fileobj()\nBUCKET_NAME = 'edu-1'\nFILE_NAME = 'efficientNetB3.h5'\nOBJECT_PATH = './edu-1/'+'efficientNetB3.h5'\n\ndef get_model():\n    s3 = boto3.client('s3')\n    with open(FILE_NAME, 'wb') as f:\n        s3.download_fileobj(BUCKET_NAME, OBJECT_PATH, f)\n    \n    # laoding the model\n    t1 = time()\n    \n    model = tf.saved_model.load(export_dir=OBJECT_PATH)\n    print(\"time for loading file size with pickle\", os.path.getsize(OBJECT_PATH)/1000,\"MB =>\", time()-t1)\n\n    return model\n\nmodel = get_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##\nThere is actually a fifth, which is the ProtoBuf format.  ProtoBuf is typically only used for deployment.  We will now convert the model we just loaded into this format.  \n\nIt is very important that this export directory be empty.  Be careful, the following command deletes the entire expor directory. (this should be fine)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: This directory structure will need to be followed - see notes for the next section\nmodel_version = '1'\nexport_path = 'export/Servo/' + model_version\n\nimport shutil\nshutil.rmtree(export_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the Protocol Buffer SavedModel at 'export_dir'\nbuild = builder.SavedModelBuilder(export_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create prediction signature to be used by TensorFlow Serving Predict API\nsignature = predict_signature_def(\n    inputs={\"inputs\": model.input}, outputs={\"score\": model.output})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.allow_soft_placement = True\n\n# Train\nwith tf.Session(config=config) as sess:\n    # Save the meta graph and variables\n    build.add_meta_graph_and_variables(\n        sess=sess, tags=[tag_constants.SERVING], \n        signature_def_map={\"serving_default\": signature})\n    build.save()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert TensorFlow model to a SageMaker readable format (must use AWS SageMaker Notebook)\n\nMove the TensorFlow exported model into a directory export\\Servo. SageMaker will recognize this as a loadable TensorFlow model. Your directory and file structure should look like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls export","execution_count":1,"outputs":[{"output_type":"stream","text":"ls: cannot access 'export': No such file or directory\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls export/Servo","execution_count":2,"outputs":[{"output_type":"stream","text":"ls: cannot access 'export/Servo': No such file or directory\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls export/Servo/1/variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tarfile\nwith tarfile.open('model.tar.gz', mode='w:gz') as archive:\n    archive.add('export', recursive=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# uploading tar to s3\nimport sagemaker\n\nsagemaker_session = sagemaker.Session()\ninputs = sagemaker_session.upload_data(path='model.tar.gz', key_prefix='model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 5. Deploy the trained model (must use AWS SageMaker Notebook)\n\nThe entry_point file \"train.py\" can be an empty Python file. The requirement will be removed at a later date."},{"metadata":{"trusted":true},"cell_type":"code","source":"!touch train.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sagemaker.tensorflow.model import TensorFlowModel\nsagemaker_model = TensorFlowModel(model_data = 's3://' + sagemaker_session.default_bucket() + '/model/model.tar.gz',\n                                  role = role,\n                                  framework_version = '1.12',\n                                  entry_point = 'train.py')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npredictor = sagemaker_model.deploy(initial_instance_count=1,\n                                   instance_type='ml.m4.xlarge')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor.endpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"endpoint_name = 'sagemaker-tensorflow-2019-08-05-03-29-25-591'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sagemaker\nfrom sagemaker.tensorflow.model import TensorFlowPredictor\npredictor= TensorFlowPredictor(endpoint_name, sagemaker_session)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 13.2.3: Test Model Deployment (optionally, outside of AWS)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport boto3\nimport numpy as np\nimport io","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pick one of the following two cells to run based on how you will access..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # If you access the API from outside of AWS SageMaker notebooks you must authenticate and specify region...\n# # (do not run both this cell and the next)\n\n# client = boto3.client('runtime.sagemaker', \n#     region_name='us-east-1', # make sure to set correct region\n#     aws_access_key_id='AKIAYKSSG3L5P2H5EU77', # These you get from AWS, for your account\n#     aws_secret_access_key='1GYDRaE1o/nFfW2nF6jAJpWrd2R5Eut/d6fS6ruL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If you access from inside AWS in a notebook (do not run both this cell and the previous)\nclient = boto3.client('runtime.sagemaker', region_name='us-east-1') # make sure to set correct region","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Call the endpoint \n\ndata = [[8,307,130,3504,12,70,1]]\n\nresponse = client.invoke_endpoint(EndpointName=endpoint_name, \n                                  Body=json.dumps(data))\nresponse_body = response['Body']\nprint(response_body.read())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}